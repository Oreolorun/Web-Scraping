{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7nPutlLoglIkgVrD/IirA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oreolorun/Web-Scraping/blob/main/WebScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fEEp5QTlb6j4"
      },
      "outputs": [],
      "source": [
        "#  Importing libraries\n",
        "from urllib.request import urlopen\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fybJtzwch0f3",
        "outputId": "8d65a6fc-361c-4f09-d235-54e7be816768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scraper Class**"
      ],
      "metadata": {
        "id": "pxhBfhwBgwcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scraper:\n",
        "  \"\"\"\n",
        "  This class is used to create an image web scraper\n",
        "  \"\"\"\n",
        "  def __init__(self, header):\n",
        "    self.header = header\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"\"\"\n",
        "    Methods Available:\n",
        "    .scrape(): extracts tags of interest\n",
        "    .download_images(): downloads images using src extracted from tags\n",
        "    .duplicate_check(): checks directory for duplicate images\n",
        "    .find_duplicates(): checks is duplicates of particular instances exits and deletes them\n",
        "    .delete_all(): deletes all instances of a list of images\n",
        "\n",
        "    \"\"\" \n",
        "    \n",
        "    \n",
        "  def scrape(self, url, tag, attribute_dict, pages=1):\n",
        "    \"\"\"\n",
        "    This method extracts img tags. Inspect to extract src.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for i in tqdm(range(pages)):\n",
        "      request = urllib.request.Request(os.path.join(url, f'?page={str(i)}'), \n",
        "                                       headers= self.header)\n",
        "      html = urlopen(request)\n",
        "      bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "      image_tags = bs.find_all(tag, attrs=attribute_dict)\n",
        "\n",
        "      for image_tag in image_tags:\n",
        "        images.append(image_tag)\n",
        "    \n",
        "    return images\n",
        "\n",
        "  def download_images(self, src_list, directory, prefix='img'):\n",
        "    \"\"\"\n",
        "    This method downloads scraped images into a specified directory\n",
        "    \"\"\"\n",
        "    try:\n",
        "      os.mkdir(directory)\n",
        "    except FileExistsError:\n",
        "      def sort_key(element):\n",
        "        return int(element.split('.')[0].split('_')[1])\n",
        "\n",
        "      file_names = os.listdir(directory)\n",
        "      file_names.sort(reverse=False, key=sort_key)\n",
        "      image_count = int(file_names[-1].split('.')[0].split('_')[1]) + 1\n",
        "\n",
        "      for src in tqdm(src_list):\n",
        "        with open(os.path.join(directory, prefix + f'_{str(image_count)}.jpg'), \n",
        "                  'wb') as f:\n",
        "                  response = requests.get(src)\n",
        "                  f.write(response.content)\n",
        "        image_count+=1\n",
        "      \n",
        "    print('Done!')\n",
        "\n",
        "  def duplicate_check(self, directory):\n",
        "    \"\"\"\n",
        "    This method checks the directory for duplicate images\n",
        "    \"\"\"\n",
        "    #  creating empyt lists to hold images\n",
        "    images = []\n",
        "    temp_list = []\n",
        "\n",
        "    #  defining a function which helps to check if an element is part of a list\n",
        "    def member(file_list, list):\n",
        "      if len(list) == 0:\n",
        "        return False\n",
        "      for li in list:\n",
        "        if np.array_equal(li[0], file_list[0]):\n",
        "          return True\n",
        "          break\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "    #  reading images into list\n",
        "    print('reading images...')\n",
        "    for f in tqdm(os.listdir(folder)):\n",
        "      try:\n",
        "        image = cv2.imread(os.path.join(folder, f), cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (20,20))\n",
        "        images.append([image, f])\n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "    #  replicating list of images\n",
        "    images_2 = [x for x in images]\n",
        "    \n",
        "    #  checking images for duplicate instances\n",
        "    print('\\nchecking images...')\n",
        "    for image in tqdm(images):\n",
        "      i=0\n",
        "      images_2.remove(image)\n",
        "      for img in images_2:\n",
        "        if np.array_equal(image[0], img[0]):\n",
        "          i+=1\n",
        "          if i==1:\n",
        "            temp_list.append(image)\n",
        "            break\n",
        "    \n",
        "    #  creating list to hold refined duplicates\n",
        "    duplicates_3 = []\n",
        "\n",
        "    #  refining list of duplicates\n",
        "    print('\\nprocessing duplicates...')\n",
        "    while len(temp_list) > 0:\n",
        "      duplicates_1 = temp_list[:]\n",
        "      duplicates_2 = temp_list[:]\n",
        "      temp_list = []\n",
        "      for image_file in tqdm(duplicates_2):\n",
        "        i=0\n",
        "        duplicates_1.remove(image_file)\n",
        "        for f in duplicates_1:\n",
        "          if np.array_equal(image_file[0], f[0]):\n",
        "            i+=1\n",
        "          break\n",
        "        if i==1:\n",
        "          temp_list.append(image_file)\n",
        "          break\n",
        "        elif i==0:\n",
        "          if member(image_file, duplicates_3) == False:\n",
        "            duplicates_3.append(image_file)\n",
        "      print(len([x[1] for x in duplicates_3]))\n",
        "          \n",
        "    #  deriving filenames form refined list\n",
        "    duplicates = [x[1] for x in duplicates_3]\n",
        "\n",
        "    #  printing to screen\n",
        "    if len(duplicates) > 1:\n",
        "      print(f'\\nThere are {len(duplicates)} duplicated instances in the dataset')\n",
        "    elif len(duplicates) == 0:\n",
        "      print(f'\\nThere are no duplicated instances in the dataset')\n",
        "    else:\n",
        "      print(f'\\nThere is {len(duplicates)} duplicated instance in the dataset')\n",
        "    return duplicates\n",
        "\n",
        "  def find_duplicates(self, directory, filenames=[]):\n",
        "    \"\"\"\n",
        "    This method checks if particular images are duplicated providing the option\n",
        "    of deleting them or not. \n",
        "    \"\"\"\n",
        "    to_check = []\n",
        "    #  creating a list to hold duplicates\n",
        "    all_duplicates = []\n",
        "\n",
        "    #  Appending duplicated images array to list\n",
        "    for f in tqdm(filenames):\n",
        "      instance = cv2.imread(os.path.join(directory, f))\n",
        "      to_check.append(instance)\n",
        "\n",
        "    #  looping through all files\n",
        "    for f in tqdm(os.listdir(directory)):\n",
        "      #  reading image files\n",
        "      image_instance = cv2.imread(os.path.join(directory, f))\n",
        "      #  looping through all images to be checked\n",
        "      for item in to_check:\n",
        "        #  comparing arrays \n",
        "        check = np.array_equal(image_instance,item)\n",
        "        if check:\n",
        "          #  appending duplicate to list if condition holds true\n",
        "          all_duplicates.append(f)\n",
        "    \n",
        "\n",
        "    if len(to_check)==len(all_duplicates):\n",
        "      print('\\nThere are no duplicated instances.')\n",
        "    else:\n",
        "      print(f'\\nTotal number of duplicates:'+ \n",
        "            f' {len(all_duplicates[len(to_check):])}')\n",
        "   \n",
        "    REQUEST_INPUT = True\n",
        "\n",
        "    while REQUEST_INPUT:\n",
        "      user_input = input('Would you like to delete duplicates? (Yes(y)/No(n)): ')\n",
        "\n",
        "      if user_input.lower() == 'y':\n",
        "        all_duplicates = [x for x in all_duplicates if x not in filenames]\n",
        "        for instance in tqdm(all_duplicates):\n",
        "          try:\n",
        "            os.remove(os.path.join(directory, instance))\n",
        "          except FileNotFoundError:\n",
        "            pass\n",
        "        print('\\nDone!')\n",
        "        REQUEST_INPUT = False\n",
        "      elif user_input.lower() == 'n':\n",
        "        print('Done!')\n",
        "        REQUEST_INPUT = False\n",
        "      else:\n",
        "        print('Invalid Input!')\n",
        "\n",
        "  def delete_all(self, directory, filenames):\n",
        "    \"\"\"\n",
        "    This method deletes all instances of a particular image. \n",
        "    \"\"\"\n",
        "    to_check = []\n",
        "    #  creating a list to hold duplicates\n",
        "    all_duplicates = []\n",
        "\n",
        "    #  Appending image instance array to list\n",
        "    for f in tqdm(filenames):\n",
        "      instance = cv2.imread(os.path.join(directory, f))\n",
        "      to_check.append(instance)\n",
        "\n",
        "    #  looping through all files\n",
        "    for f in tqdm(os.listdir(directory)):\n",
        "      #  reading image files\n",
        "      image_instance = cv2.imread(os.path.join(directory, f))\n",
        "      #  looping through all images to be checked\n",
        "      for item in to_check:\n",
        "        #  comparing arrays \n",
        "        check = np.array_equal(image_instance,item)\n",
        "        if check:\n",
        "          #  appending duplicate to list if condition holds true\n",
        "          all_duplicates.append(f)\n",
        "    \n",
        "    while True:\n",
        "      user_input = input(f'There are/is {len(all_duplicates)} instances in this dataset.'+\n",
        "                        \"\\nConfirm deletion (Confirm(c)/Cancel(x)): \") \n",
        "      \n",
        "      if user_input.lower() == 'c': \n",
        "        #  deleting images\n",
        "        try:\n",
        "          for instance in all_duplicates:\n",
        "            os.remove(os.path.join(directory, instance))\n",
        "        except FileNotFoundError:\n",
        "          pass\n",
        "        break\n",
        "      elif user_input.lower() == 'x':\n",
        "        pass\n",
        "        break\n",
        "      else:\n",
        "        print('Invalid Input!\\n')\n",
        "    print('\\nDone!')"
      ],
      "metadata": {
        "id": "0Fyl1kmRJe0S"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "      'Accept-Encoding': 'none',\n",
        "      'Accept-Language': 'en-US,en;q=0.8',\n",
        "      'Connection': 'keep-alive'}\n",
        "\n",
        "url = 'https://www.truecar.com/used-cars-for-sale/listings/body-coupe/location-georgetown-pa/'\n",
        "\n",
        "attrs = {'class':'img-inner img-block img-crop'}\n",
        "\n",
        "image_scraper = Scraper(header=header)"
      ],
      "metadata": {
        "id": "smd1nlVfZ3kJ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3]\n",
        "b = [1]\n",
        "\n",
        "a = [x for x in a if x not in b]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03lvn6SaLBqK",
        "outputId": "83207905-e6e5-4dba-8cd7-74986ce2e51f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = image_scraper.scrape(url, 'img', attrs, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rt-1QuaWk32",
        "outputId": "a623e0b4-ff3d-477b-b4d1-fa5b7c8ba2fc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = [x['style'][21:-1] for x in tags]\n",
        "\n",
        "folder = 'gdrive/My Drive/Datasets/from_scraper'\n",
        "\n",
        "image_scraper.download_images(src[:5], folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p6Q4YUKYFuB",
        "outputId": "71ef600a-77a7-4dda-cfc3-dd2ff9ac1161"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 30.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_key(element):\n",
        "  return int(element.split('.')[0].split('_')[1])"
      ],
      "metadata": {
        "id": "_OGnpvaYPznc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_2 = 'gdrive/My Drive/Datasets/Car_Images/sedans'\n",
        "folder = 'gdrive/My Drive/Datasets/from_scraper'\n",
        "\n",
        "image_scraper.duplicate_check(folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe0T5nJfbsN6",
        "outputId": "7b69cf96-0c5d-42e2-aeaa-cb2bd64ccd6d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [00:00<00:00, 259.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "checking images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [00:00<00:00, 3535.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "processing duplicates...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 31488.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "\n",
            "There are 9 duplicated instances in the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_6.jpg',\n",
              " 'img_102.jpg',\n",
              " 'img_103.jpg',\n",
              " 'img_123.jpg',\n",
              " 'img_124.jpg',\n",
              " 'img_125.jpg',\n",
              " 'img_126.jpg',\n",
              " 'img_127.jpg',\n",
              " 'img_128.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_scraper.find_duplicates(folder, ['img_6.jpg',\n",
        "                                      'img_102.jpg',\n",
        "                                      'img_103.jpg',\n",
        "                                      'img_123.jpg',\n",
        "                                      'img_124.jpg',\n",
        "                                      'img_125.jpg',\n",
        "                                      'img_126.jpg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J7eRVL7sczM",
        "outputId": "4236e686-fa2b-4288-c135-4962173b1c0b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 184.42it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 206.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of duplicates: 12\n",
            "Would you like to delete duplicates? (Yes(y)/No(n)): y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 648.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_scraper.delete_all(folder, ['img_122.jpg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myd91oVJd4_5",
        "outputId": "7eff7cc5-e5ed-482e-abac-bcaef78b08a3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 97.91it/s]\n",
            "100%|██████████| 119/119 [00:00<00:00, 169.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are/is 1 instances in this dataset.\n",
            "Confirm deletion (Confirm(c)/Cancel(x)): g\n",
            "Invalid Input!\n",
            "\n",
            "There are/is 1 instances in this dataset.\n",
            "Confirm deletion (Confirm(c)/Cancel(x)): x\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(folder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIlHUzyiaVnO",
        "outputId": "b28fc50e-deca-4fad-85ba-de5f9b4dc6a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for duplicates"
      ],
      "metadata": {
        "id": "AeNdRjtN57pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Checking for duplicates\n",
        "FLAG_30 = False\n",
        "\n",
        "while FLAG_30:\n",
        "  #  creating list to hold images\n",
        "  image_holder = []\n",
        "\n",
        "  #  appending image array to list\n",
        "  print('appending images to list...')\n",
        "  for f in tqdm(os.listdir()):\n",
        "    f_temp = cv2.imread(f)\n",
        "    image_holder.append(f_temp)\n",
        "  \n",
        "  #  creating a queue of images\n",
        "  print('populating placeholder list...')\n",
        "  image_holder_queue = [x for x in image_holder]\n",
        "\n",
        "  #  creating a list to hold duplicates\n",
        "  duplicate_element = []\n",
        "  k = 0\n",
        "\n",
        "  print('checking for duplicates...')\n",
        "  #  looping through images\n",
        "  for element in tqdm(image_holder):\n",
        "    try:\n",
        "      image_holder_queue.remove(element)\n",
        "      for item in image_holder_queue:\n",
        "        check = np.array_equal(element, item)\n",
        "        if check:\n",
        "          for arr in duplicate_element:\n",
        "            if not np.array_equal(element, arr):\n",
        "              duplicate_element.append(element)\n",
        "              k+=1\n",
        "    except TypeError:\n",
        "      pass\n",
        "  print(f'\\nThere are {len(duplicate_element)} duplicates in this directory')\n",
        "  break "
      ],
      "metadata": {
        "id": "IZVTCpqURbP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_check(directory):\n",
        "  #  creating empty lists to hold image arrays\n",
        "  images, images_temp = [], []\n",
        "  #  creating a list to hold file names\n",
        "  file_names = []\n",
        "\n",
        "  #  reading images\n",
        "  print('reading images...')\n",
        "  for img_file in tqdm(os.listdir(directory)):\n",
        "    try:\n",
        "      f = cv2.imread(os.path.join(directory, img_file))\n",
        "      f = cv2.resize(f, (20,20)) #  resizing\n",
        "      file_names.append(img_file) \n",
        "      images.append(f) #  appending to list\n",
        "      images_temp.append(f)\n",
        "    except Exception:\n",
        "      pass\n",
        "\n",
        "  i=0 #  counter\n",
        "  duplicate_idx = []\n",
        "  #  looping through images\n",
        "  print('checking images...')\n",
        "  for image in tqdm(images):\n",
        "    images_temp.remove(image)\n",
        "    for img in images_temp:\n",
        "      if np.array_equal(image, img):\n",
        "        duplicate_idx.append(i)\n",
        "    i+=1\n",
        "\n",
        "  if len(set(duplicate_idx))>1:\n",
        "    file_refresh = []\n",
        "    for idx in list(set(duplicate_idx)):\n",
        "      file_refresh.append(file_names[idx])\n",
        "\n",
        "\n",
        "    while len(set(duplicate_idx))>0:\n",
        "      img = []\n",
        "      img_temp = []\n",
        "      duplicate_refresh = duplicate_idx[:]\n",
        "      duplicate_idx = []\n",
        "\n",
        "      print('processing...')\n",
        "      for idx in tqdm(list(set(duplicate_refresh))):\n",
        "        img.append(images[idx])\n",
        "        img_temp.append(images[idx])\n",
        "\n",
        "      k=0\n",
        "      for image in tqdm(img):\n",
        "        img_temp.remove(image)\n",
        "        for im in img_temp:\n",
        "          if np.array_equal(image, im):\n",
        "            duplicate_idx.append(k)\n",
        "        k+=1\n",
        "      file_temp = []\n",
        "      for idx in list(set(duplicate_idx)):\n",
        "        file_temp.append(file_refresh[idx])\n",
        "        print(file_temp)\n",
        "      file_refresh = file_temp[:]\n",
        "    \n",
        "    print(f'\\nThere are/is {len(set(duplicate_refresh))} instances with duplicates in the dataset')\n",
        "    print('*'*55)\n",
        "\n",
        "    if len(set(duplicate_refresh)) > 0:\n",
        "      #  deriving duplicate file names\n",
        "      print('\\nderiving filenames...')\n",
        "      print(set(duplicate_refresh))\n",
        "      print(file_refresh)\n",
        "      duplicated_instances = []\n",
        "      for idx in tqdm(list(set(duplicate_refresh))):\n",
        "        duplicated_instances.append(file_refresh[idx])\n",
        "      return duplicated_instances\n",
        "    else:\n",
        "      print('\\nNo duplicates found.')\n",
        "      return None\n",
        "\n",
        "  elif len(set(duplicate_idx)) == 1:\n",
        "    print(f'\\n\\nThere are/is {len(set(duplicate_idx))} instances with duplicates in the dataset')\n",
        "    print('*'*55)\n",
        "\n",
        "    print('\\nderiving filename...')\n",
        "    print('Done!')\n",
        "    return [file_names[duplicate_idx[0]]]\n",
        "  \n",
        "  else:\n",
        "    print('\\nThere are no duplicates')\n",
        "    return None"
      ],
      "metadata": {
        "id": "A_N8Pj-DdZWn"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_2 = 'gdrive/My Drive/Datasets/Car_Images/sedans'\n",
        "temp = duplicate_check(folder)"
      ],
      "metadata": {
        "id": "OBZ9rqYyiD5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "id": "YEDtVyCU0gdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "id": "lgQqYUYBGIV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_check_x(directory):\n",
        "  #  creating empty lists to hold image arrays\n",
        "  images, images_temp = [], []\n",
        "  #  creating a list to hold file names\n",
        "  file_names = []\n",
        "  files = []\n",
        "\n",
        "  #  reading images\n",
        "  print('reading images...')\n",
        "  for img_file in tqdm(os.listdir(directory)):\n",
        "    try:\n",
        "      f = cv2.imread(os.path.join(directory, img_file))\n",
        "      f = cv2.resize(f, (20,20)) #  resizing\n",
        "      file_names.append(img_file)\n",
        "      files.append([f,img_file]) \n",
        "      images.append(f) #  appending to list\n",
        "      images_temp.append(f)\n",
        "    except Exception:\n",
        "      pass\n",
        "\n",
        "  i=0 #  counter\n",
        "  duplicate_idx = []\n",
        "  #  looping through images\n",
        "  print('checking images...')\n",
        "  for image in tqdm(images):\n",
        "    images_temp.remove(image)\n",
        "    for img in images_temp:\n",
        "      if np.array_equal(image, img):\n",
        "        duplicate_idx.append(i)\n",
        "    i+=1\n",
        "\n",
        "  if len(set(duplicate_idx))>1:\n",
        "    file_refresh = []\n",
        "    for idx in list(set(duplicate_idx)):\n",
        "      file_refresh.append(files[idx])\n",
        "\n",
        "\n",
        "    while len(set(duplicate_idx))>0:\n",
        "      duplicate_refresh = duplicate_idx[:]\n",
        "      duplicate_idx = []\n",
        "\n",
        "      print('processing...')\n",
        "      for idx in tqdm(list(set(duplicate_refresh))):\n",
        "        img = [x[0] for x in file_refresh]\n",
        "        img_temp = [x for x in img]\n",
        "\n",
        "      k=0\n",
        "      for image in tqdm(img):\n",
        "        img_temp.remove(image)\n",
        "        for im in img_temp:\n",
        "          if np.array_equal(image, im):\n",
        "            duplicate_idx.append(k)\n",
        "        k+=1\n",
        "      file_temp = []\n",
        "      for idx in list(set(duplicate_idx)):\n",
        "        file_temp.append(file_refresh[idx])\n",
        "        print(f'file temp: {file_temp}')\n",
        "      file_refresh = file_temp[:]\n",
        "      print(f'file refresh: {file_refresh}')\n",
        "    \n",
        "    print(f'\\nThere are/is {len(set(duplicate_refresh))} instances with duplicates in the dataset')\n",
        "    print('*'*55)\n",
        "\n",
        "    if len(set(duplicate_refresh)) > 0:\n",
        "      #  deriving duplicate file names\n",
        "      print('\\nderiving filenames...')\n",
        "      print(set(duplicate_refresh))\n",
        "      print(file_refresh)\n",
        "      duplicated_instances = []\n",
        "      for idx in tqdm(list(set(duplicate_refresh))):\n",
        "        duplicated_instances.append(file_refresh[idx])\n",
        "      return duplicated_instances\n",
        "    else:\n",
        "      print('\\nNo duplicates found.')\n",
        "      return None\n",
        "\n",
        "  elif len(set(duplicate_idx)) == 1:\n",
        "    print(f'\\n\\nThere are/is {len(set(duplicate_idx))} instances with duplicates in the dataset')\n",
        "    print('*'*55)\n",
        "\n",
        "    print('\\nderiving filename...')\n",
        "    print('Done!')\n",
        "    return [file_names[duplicate_idx[0]]]\n",
        "  \n",
        "  else:\n",
        "    print('\\nThere are no duplicates')\n",
        "    return None"
      ],
      "metadata": {
        "id": "HrpyBKcW5RcU"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  deriving filenames\n",
        "filenames = os.listdir(folder)\n",
        "\n",
        "#  sorting in ascending order\n",
        "filenames.sort(reverse=False)\n",
        "\n",
        "#  first 15 files\n",
        "filenames[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV4xLzBsCmVa",
        "outputId": "01d13873-cbf1-4ec0-b517-84cb122c7a20"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_10.jpg',\n",
              " 'img_100.jpg',\n",
              " 'img_101.jpg',\n",
              " 'img_102.jpg',\n",
              " 'img_103.jpg',\n",
              " 'img_105.jpg',\n",
              " 'img_106.jpg',\n",
              " 'img_107.jpg',\n",
              " 'img_108.jpg',\n",
              " 'img_109.jpg',\n",
              " 'img_11.jpg',\n",
              " 'img_110.jpg',\n",
              " 'img_111.jpg',\n",
              " 'img_112.jpg',\n",
              " 'img_113.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_key(element):\n",
        "  return int(element.split('.')[0].split('_')[1])\n",
        "\n",
        "#  sorting with the sort function\n",
        "filenames.sort(reverse=False, key=sort_key)\n",
        "\n",
        "#  first 15 files\n",
        "filenames[:15]"
      ],
      "metadata": {
        "id": "xFFZjJ4xJVxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dupli_check(folder):\n",
        "  #  creating empyt lists to hold images\n",
        "  images = []\n",
        "  temp_list = []\n",
        "\n",
        "  #  defining a function which helps to check if an element is part of a list\n",
        "  def member(file_list, list):\n",
        "    if len(list) == 0:\n",
        "      return False\n",
        "    for li in list:\n",
        "      if np.array_equal(li[0], file_list[0]):\n",
        "        return True\n",
        "        break\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "  #  reading images into list\n",
        "  print('reading images...')\n",
        "  for f in tqdm(os.listdir(folder)):\n",
        "    try:\n",
        "      image = cv2.imread(os.path.join(folder, f), cv2.IMREAD_GRAYSCALE)\n",
        "      image = cv2.resize(image, (20,20))\n",
        "      images.append([image, f])\n",
        "    except Exception:\n",
        "      pass\n",
        "\n",
        "  #  replicating list of images\n",
        "  images_2 = [x for x in images]\n",
        "  \n",
        "  #  checking images for duplicate instances\n",
        "  print('\\nchecking images...')\n",
        "  for image in tqdm(images):\n",
        "    i=0\n",
        "    images_2.remove(image)\n",
        "    for img in images_2:\n",
        "      if np.array_equal(image[0], img[0]):\n",
        "        i+=1\n",
        "        if i==1:\n",
        "          temp_list.append(image)\n",
        "          break\n",
        "  \n",
        "  #  creating list to hold refined duplicates\n",
        "  duplicates_3 = []\n",
        "\n",
        "  #  refining list of duplicates\n",
        "  print('\\nprocessing duplicates...')\n",
        "  while len(temp_list) > 0:\n",
        "    duplicates_1 = temp_list[:]\n",
        "    duplicates_2 = temp_list[:]\n",
        "    temp_list = []\n",
        "    for image_file in tqdm(duplicates_2):\n",
        "      i=0\n",
        "      duplicates_1.remove(image_file)\n",
        "      for f in duplicates_1:\n",
        "        if np.array_equal(image_file[0], f[0]):\n",
        "          i+=1\n",
        "        break\n",
        "      if i==1:\n",
        "        temp_list.append(image_file)\n",
        "        break\n",
        "      elif i==0:\n",
        "        if member(image_file, duplicates_3) == False:\n",
        "          duplicates_3.append(image_file)############\n",
        "    print(len([x[1] for x in duplicates_3]))\n",
        "        \n",
        "  #  deriving filenames form refined list\n",
        "  duplicates = [x[1] for x in duplicates_3]\n",
        "\n",
        "  #  printing to screen\n",
        "  if len(duplicates) > 1:\n",
        "    print(f'\\nThere are {len(duplicates)} duplicated instances in the dataset')\n",
        "  elif len(duplicates) == 0:\n",
        "    print(f'\\nThere are no duplicated instances in the dataset')\n",
        "  else:\n",
        "    print(f'\\nThere is {len(duplicates)} duplicated instance in the dataset')\n",
        "  return duplicates"
      ],
      "metadata": {
        "id": "LqvDh2zFMTrl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = 'gdrive/My Drive/Datasets/from_scraper'\n",
        "folder_2 = 'gdrive/My Drive/Datasets/Car_Images/sedans'\n",
        "dup = dupli_check(folder_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftAnJlHLMfvm",
        "outputId": "e59dbf19-7635-42a6-bce3-f4fc102fecfb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20290/20290 [08:01<00:00, 42.13it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "checking images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20288/20288 [15:45<00:00, 21.45it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "processing duplicates...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 3612/6096 [00:00<00:00, 69851.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3613\n",
            "\n",
            "There are 3613 duplicated instances in the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dup[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRuphyGPhGZD",
        "outputId": "4dce75d7-ca4f-4c05-f4bb-663b0f5cf163"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sedan_45202.jpg',\n",
              " 'sedan_45203.jpg',\n",
              " 'sedan_45204.jpg',\n",
              " 'sedan_45205.jpg',\n",
              " 'sedan_45206.jpg',\n",
              " 'sedan_45207.jpg',\n",
              " 'sedan_45209.jpg',\n",
              " 'sedan_45210.jpg',\n",
              " 'sedan_45211.jpg',\n",
              " 'sedan_45214.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def member(file_list, list):\n",
        "  if len(list) == 0:\n",
        "    return False\n",
        "  for li in list:\n",
        "    if np.array_equal(li[0], file_list[0]):\n",
        "      return True\n",
        "      break\n",
        "    else:\n",
        "      return False"
      ],
      "metadata": {
        "id": "79ARx4YHRG-T"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}