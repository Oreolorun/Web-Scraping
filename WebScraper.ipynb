{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1gUUP5zGSkNRjAfNktaHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oreolorun/Web-Scraping/blob/main/WebScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEEp5QTlb6j4"
      },
      "outputs": [],
      "source": [
        "#  Importing libraries\n",
        "from urllib.request import urlopen\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fybJtzwch0f3",
        "outputId": "bf62e010-318f-4907-cc1e-4e505be41522"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scraper Class**"
      ],
      "metadata": {
        "id": "pxhBfhwBgwcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scraper:\n",
        "  \"\"\"\n",
        "  This class is used to create an image web scraper\n",
        "  \"\"\"\n",
        "  def __init__(self, header, directory):\n",
        "    #  initialization\n",
        "    self.header = header\n",
        "    self.directory = directory\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"\"\"\n",
        "    Methods Available:\n",
        "    .scrape(): extracts tags of interest\n",
        "    .download_images(): downloads images using src extracted from tags\n",
        "    .duplicate_check(): checks directory for duplicate images\n",
        "    .find_duplicates(): checks is duplicates of particular instances exits and deletes them\n",
        "    .delete_all(): deletes all instances of a list of images\n",
        "\n",
        "    \"\"\" \n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"\"\"\n",
        "    working directory: {self.directory}\n",
        "    header: {self.header}\n",
        "    \"\"\"\n",
        "\n",
        "  def scrape(self, url, tag, attribute_dict, pages=1):\n",
        "    \"\"\"\n",
        "    This method extracts img tags. Inspect to extract src.\n",
        "    \"\"\"\n",
        "    #  importing libraries\n",
        "    from urllib.request import urlopen\n",
        "    import urllib.request\n",
        "    from bs4 import BeautifulSoup\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import requests\n",
        "    import cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    images = []\n",
        "    for i in tqdm(range(pages)):\n",
        "      request = urllib.request.Request(os.path.join(url, f'?page={str(i)}'), \n",
        "                                       headers= self.header)\n",
        "      html = urlopen(request)\n",
        "      bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "      image_tags = bs.find_all(tag, attrs=attribute_dict)\n",
        "\n",
        "      for image_tag in image_tags:\n",
        "        images.append(image_tag)\n",
        "    \n",
        "    return images\n",
        "\n",
        "  def download_images(self, src_list, prefix='img'):\n",
        "    \"\"\"\n",
        "    This method downloads scraped images into a specified directory\n",
        "    \"\"\"\n",
        "    #  importing libraries\n",
        "    from urllib.request import urlopen\n",
        "    import urllib.request\n",
        "    from bs4 import BeautifulSoup\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import requests\n",
        "    import cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    try:\n",
        "      os.mkdir(self.directory)\n",
        "    except FileExistsError:\n",
        "      def sort_key(element):\n",
        "        return int(element.split('.')[0].split('_')[1])\n",
        "\n",
        "      file_names = os.listdir(self.directory)\n",
        "      file_names.sort(reverse=False, key=sort_key)\n",
        "      image_count = int(file_names[-1].split('.')[0].split('_')[1]) + 1\n",
        "\n",
        "      for src in tqdm(src_list):\n",
        "        with open(os.path.join(self.directory, prefix + f'_{str(image_count)}.jpg'), \n",
        "                  'wb') as f:\n",
        "                  response = requests.get(src)\n",
        "                  f.write(response.content)\n",
        "        image_count+=1\n",
        "      \n",
        "    print('Done!')\n",
        "\n",
        "  def duplicate_check(self):\n",
        "    \"\"\"\n",
        "    This method checks for the presence of duplicate images in the directory\n",
        "    \"\"\"\n",
        "    #  importing libraries\n",
        "    from urllib.request import urlopen\n",
        "    import urllib.request\n",
        "    from bs4 import BeautifulSoup\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import requests\n",
        "    import cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    #  creating empyt lists to hold images\n",
        "    images = []\n",
        "    temp_list = []\n",
        "\n",
        "    #  defining a function which helps to check if an element is part of a list\n",
        "    def gate(file_list, master_list):\n",
        "      if len(master_list) == 0:\n",
        "        return 'allow'\n",
        "      #  function logic\n",
        "      access = []\n",
        "      for li in master_list:\n",
        "        check = np.array_equal(file_list[0], li[0])\n",
        "        access.append(check)\n",
        "        if check == True:\n",
        "          break\n",
        "      #  return statement\n",
        "      if True in access:\n",
        "        return 'deny'\n",
        "      else:\n",
        "        return 'allow'\n",
        "\n",
        "    #  reading images into list\n",
        "    print('reading images...')\n",
        "    for f in tqdm(os.listdir(self.directory)):\n",
        "      try:\n",
        "        image = cv2.imread(os.path.join(self.directory, f), cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (20,20))\n",
        "        images.append([image, f])\n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "    #  replicating list of images\n",
        "    images_2 = [x for x in images]\n",
        "    \n",
        "    #  checking images for duplicate instances\n",
        "    print('\\nchecking images...')\n",
        "    for image in tqdm(images):\n",
        "      i=0\n",
        "      images_2.remove(image)\n",
        "      for img in images_2:\n",
        "        if np.array_equal(image[0], img[0]):\n",
        "          i+=1\n",
        "          if i==1:\n",
        "            temp_list.append(image)\n",
        "            break\n",
        "    \n",
        "    #  creating list to hold refined duplicates\n",
        "    duplicates_3 = []\n",
        "\n",
        "    #  refining list of duplicates\n",
        "    print('processing...')\n",
        "    for image_file in tqdm(temp_list):\n",
        "      if gate(image_file, duplicates_3)=='allow':\n",
        "        duplicates_3.append(image_file)\n",
        "          \n",
        "    #  deriving filenames form refined list\n",
        "    duplicates = [x[1] for x in duplicates_3]\n",
        "\n",
        "    #  printing to screen\n",
        "    if len(duplicates) > 1:\n",
        "      print(f'\\nThere are {len(duplicates)} duplicated instances in the dataset')\n",
        "    elif len(duplicates) == 0:\n",
        "      print(f'\\nThere are no duplicated instances in the dataset')\n",
        "    else:\n",
        "      print(f'\\nThere is {len(duplicates)} duplicated instance in the dataset')\n",
        "    return duplicates\n",
        "\n",
        "  def find_duplicates(self, filenames=[]):\n",
        "    \"\"\"\n",
        "    This method checks if particular images are duplicated providing the option\n",
        "    of deleting them or not. \n",
        "    \"\"\"\n",
        "    #  importing libraries\n",
        "    from urllib.request import urlopen\n",
        "    import urllib.request\n",
        "    from bs4 import BeautifulSoup\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import requests\n",
        "    import cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    to_check = []\n",
        "    #  creating a list to hold duplicates\n",
        "    all_duplicates = []\n",
        "\n",
        "    #  Appending duplicated images array to list\n",
        "    for f in tqdm(filenames):\n",
        "      instance = cv2.imread(os.path.join(self.directory, f))\n",
        "      to_check.append(instance)\n",
        "\n",
        "    #  looping through all files\n",
        "    for f in tqdm(os.listdir(self.directory)):\n",
        "      #  reading image files\n",
        "      image_instance = cv2.imread(os.path.join(self.directory, f))\n",
        "      #  looping through all images to be checked\n",
        "      for item in to_check:\n",
        "        #  comparing arrays \n",
        "        check = np.array_equal(image_instance,item)\n",
        "        if check:\n",
        "          #  appending duplicate to list if condition holds true\n",
        "          all_duplicates.append(f)\n",
        "    \n",
        "\n",
        "    if len(to_check)==len(all_duplicates):\n",
        "      print('\\nThere are no duplicated instances.')\n",
        "    else:\n",
        "      print(f'\\nTotal number of duplicates:'+ \n",
        "            f' {len(all_duplicates[len(to_check):])}')\n",
        "   \n",
        "    request_input = True\n",
        "\n",
        "    while request_input:\n",
        "      user_input = input('Would you like to delete duplicates? (Yes(y)/No(n)): ')\n",
        "\n",
        "      if user_input.lower() == 'y':\n",
        "        all_duplicates = [x for x in all_duplicates if x not in filenames]\n",
        "        for instance in tqdm(all_duplicates):\n",
        "          try:\n",
        "            os.remove(os.path.join(self.directory, instance))\n",
        "          except FileNotFoundError:\n",
        "            pass\n",
        "        print('\\nDone!')\n",
        "        request_input = False\n",
        "      elif user_input.lower() == 'n':\n",
        "        print('Done!')\n",
        "        request_input = False\n",
        "      else:\n",
        "        print('Invalid Input!')\n",
        "\n",
        "  def delete_all(self, filenames):\n",
        "    \"\"\"\n",
        "    This method deletes all instances of a particular image. \n",
        "    \"\"\"\n",
        "    #  importing libraries\n",
        "    from urllib.request import urlopen\n",
        "    import urllib.request\n",
        "    from bs4 import BeautifulSoup\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import requests\n",
        "    import cv2\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    to_check = []\n",
        "    #  creating a list to hold duplicates\n",
        "    all_duplicates = []\n",
        "\n",
        "    #  Appending image instance array to list\n",
        "    for f in tqdm(filenames):\n",
        "      instance = cv2.imread(os.path.join(self.directory, f))\n",
        "      to_check.append(instance)\n",
        "\n",
        "    #  looping through all files\n",
        "    for f in tqdm(os.listdir(self.directory)):\n",
        "      #  reading image files\n",
        "      image_instance = cv2.imread(os.path.join(self.directory, f))\n",
        "      #  looping through all images to be checked\n",
        "      for item in to_check:\n",
        "        #  comparing arrays \n",
        "        check = np.array_equal(image_instance,item)\n",
        "        if check:\n",
        "          #  appending duplicate to list if condition holds true\n",
        "          all_duplicates.append(f)\n",
        "    \n",
        "    while True:\n",
        "      user_input = input(f'There are/is {len(all_duplicates)} instances in this dataset.'+\n",
        "                        \"\\nConfirm deletion (Confirm(c)/Cancel(x)): \") \n",
        "      \n",
        "      if user_input.lower() == 'c': \n",
        "        #  deleting images\n",
        "        try:\n",
        "          for instance in all_duplicates:\n",
        "            os.remove(os.path.join(self.directory, instance))\n",
        "        except FileNotFoundError:\n",
        "          pass\n",
        "        break\n",
        "      elif user_input.lower() == 'x':\n",
        "        pass\n",
        "        break\n",
        "      else:\n",
        "        print('Invalid Input!\\n')\n",
        "    print('\\nDone!')"
      ],
      "metadata": {
        "id": "0Fyl1kmRJe0S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating objects\n",
        "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "      'Accept-Encoding': 'none',\n",
        "      'Accept-Language': 'en-US,en;q=0.8',\n",
        "      'Connection': 'keep-alive'}\n",
        "\n",
        "url = 'https://www.truecar.com/used-cars-for-sale/listings/body-coupe/location-georgetown-pa/'\n",
        "\n",
        "directory = 'gdrive/My Drive/Datasets/from_scraper'\n",
        "\n",
        "attrs = {'class':'img-inner img-block img-crop'}\n",
        "\n",
        "#  instantiating scraper\n",
        "image_scraper = Scraper(header=header, directory=directory)"
      ],
      "metadata": {
        "id": "smd1nlVfZ3kJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  scraping 4 pages\n",
        "tags = image_scraper.scrape(url, 'img', attrs, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rt-1QuaWk32",
        "outputId": "2adbdf39-e339-4290-c51b-eb7687321e39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:06<00:00,  1.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  extracting src links from tags after inspection\n",
        "src = [x['style'][21:-1] for x in tags]\n",
        "\n",
        "#  downloading images\n",
        "image_scraper.download_images(src[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p6Q4YUKYFuB",
        "outputId": "36c24b05-7453-4b3e-f163-c72c8d3b514c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00,  7.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  checking for duplicates\n",
        "image_scraper.duplicate_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe0T5nJfbsN6",
        "outputId": "d1c59f7d-1c05-4bae-c4fa-101d4713503d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:00<00:00, 207.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "checking images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:00<00:00, 3258.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 8360.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 3 duplicated instances in the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_86.jpg', 'img_102.jpg', 'img_103.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  find and deleting all duplicated instances\n",
        "image_scraper.find_duplicates(['img_86.jpg',\n",
        "                               'img_102.jpg',\n",
        "                               'img_103.jpg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J7eRVL7sczM",
        "outputId": "32d82bd4-a665-4b89-ff40-603a7b120481"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 101.23it/s]\n",
            "100%|██████████| 93/93 [00:00<00:00, 189.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of duplicates: 3\n",
            "Would you like to delete duplicates? (Yes(y)/No(n)): y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 381.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  deleting a particular image or all instances of said image\n",
        "image_scraper.delete_all(['img_122.jpg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myd91oVJd4_5",
        "outputId": "fc6221d9-c030-4346-9041-e66afc7ad298"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 92.26it/s]\n",
            "100%|██████████| 90/90 [00:00<00:00, 184.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are/is 1 instances in this dataset.\n",
            "Confirm deletion (Confirm(c)/Cancel(x)): x\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}